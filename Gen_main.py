# Import necessary libraries
from __future__ import print_function
import os
import time
import numpy as np
import cv2
import torch
from torchvision import utils as vutils
from torch import nn, optim
import torch.nn.functional as F
import torch.utils.data
import torchvision.transforms as transforms
from torch.autograd import Variable
from torchvision import datasets
from torchvision.utils import save_image, make_grid
import matplotlib.pyplot as plt

from Discriminator import D
from Generator import G
from tqdm import tqdm_notebook as tqdm

# Configuration and Hyperparameters
data_dir = "GTSRB"
train_dataset_dir = os.path.join(data_dir, "Train")
test_dataset_dir = os.path.join(data_dir, "Test")
channels = 3
batch_size = 32
image_size = 64  # Desired image size (width and height)
NUM_CATEGORIES = len(os.listdir(train_dataset_dir))  # Total number of categories/classes

d_losses = []
g_losses = []


# Function to Load Data
def load_data(data_dir, width, height):
    images = []
    labels = []
    for class_folder in os.listdir(data_dir):
        class_path = os.path.join(data_dir, class_folder)
        for image_file in os.listdir(class_path):
            img = cv2.imread(os.path.join(class_path, image_file))
            img = cv2.resize(img, (width, height))
            images.append(img)
            labels.append(int(class_folder))
    return np.array(images), np.array(labels)


# Define Transformations
transform = transforms.Compose([
    transforms.Resize((image_size, image_size)),
    transforms.CenterCrop(image_size),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

# Load Train Data Using PyTorch ImageFolder
train_data = datasets.ImageFolder(train_dataset_dir, transform=transform)

# Create DataLoader
dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)

# Retrieve a Batch of Images and Labels for Visualization
imgs, labels = next(iter(dataloader))
imgs = imgs.numpy().transpose(0, 2, 3, 1)  # Convert from (B, C, H, W) to (B, H, W, C) for visualization


# Optional: Display the First Batch of Images
def show_images(imgs, labels, num_images=8):
    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))
    for i in range(num_images):
        ax = axes[i]
        ax.imshow((imgs[i] * 0.5 + 0.5))  # Unnormalize for display
        ax.axis("off")
    plt.show()


show_images(imgs, labels)


def weights_init(m):
    """
    Takes as input a neural network m that will initialize all its weights.
    """
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        m.weight.data.normal_(0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        m.weight.data.normal_(1.0, 0.02)
        m.bias.data.fill_(0)


# Creating the generator
netG = G()
netG.apply(weights_init)

# Creating the discriminator
netD = D()
netD.apply(weights_init)

EPOCH = 10 # play with me
LR_G = 0.0001
LR_D = 0.0001
criterion = nn.BCELoss()
optimizerD = optim.Adam(netD.parameters(), lr=LR_D, betas=(0.5, 0.999))
optimizerG = optim.Adam(netG.parameters(), lr=LR_G, betas=(0.5, 0.999))

for epoch in range(EPOCH):
    for i, data in enumerate(dataloader, 0):
        # 1st Step: Updating the weights of the neural network of the discriminator
        netD.zero_grad()

        # Training the discriminator with a real_scenes image of the dataset
        real, _ = data
        input = Variable(real)
        target = Variable(torch.ones(input.size()[0]))
        output = netD(input)
        errD_real = criterion(output, target)

        # Training the discriminator with a fake_scenes image generated by the generator
        noise = Variable(torch.randn(input.size()[0], 100, 1, 1))
        fake = netG(noise)
        target = Variable(torch.zeros(input.size()[0]))
        output = netD(fake.detach())
        errD_fake = criterion(output, target)

        # Backpropagating the total error
        errD = errD_real + errD_fake
        errD.backward()
        optimizerD.step()

        # 2nd Step: Updating the weights of the neural network of the generator
        for _ in range(3):  # Train generator 3 times for every discriminator update
            netG.zero_grad()
            target = Variable(torch.ones(input.size()[0]))  # Labels for generator are all ones to fool discriminator
            output = netD(fake)  # Re-run discriminator on fake_scenes images
            errG = criterion(output, target)
            errG.backward()
            optimizerG.step()

            # Generate new fake_scenes images for each generator update
            fake = netG(noise)

        # Store losses for plotting
        d_losses.append(errD.item())
        g_losses.append(errG.item())


        # 3rd Step: Printing the losses and saving the generated images of the minibatch every 100 steps in the last epoch
        print(
            '[%d/%d][%d/%d] Loss_D: %.4f; Loss_G: %.4f' % (epoch, EPOCH, i, len(dataloader), errD.item(), errG.item()))
        if epoch == EPOCH - 1 and i % 100 == 0:
            # Generate fake samples and save them
            fake = netG(noise)
            # Set the number of additional batches to generate per step
            additional_batches = 5  # Number of extra batches of fake examples

            # Save the initial batch of generated fake images
            output_dir = f'GTSRB/Test/fake_samples_epoch_{epoch}_step_{i}'
            os.makedirs(output_dir, exist_ok=True)

            # Save the first batch of fake images
            for idx, img in enumerate(fake):
                save_path = os.path.join(output_dir, f'fake_sample_{idx + 1}.png')
                save_image(img, save_path, normalize=True)

            # Generate additional batches of fake examples
            for batch_num in range(1, additional_batches + 1):
                noise = Variable(torch.randn(batch_size, 100, 1, 1))  # Generate new noise for each batch
                extra_fake = netG(noise)  # Generate new fake samples

                # Save each image from the additional batch
                for idx, img in enumerate(extra_fake):
                    save_path = os.path.join(output_dir, f'fake_sample_{batch_num * batch_size + idx + 1}.png')
                    save_image(img, save_path, normalize=True)

            print(f"Generated and saved {additional_batches * batch_size + len(fake)} fake images in {output_dir}")

            # Plot and save the loss graph
            plt.figure(figsize=(10, 5))
            plt.plot(d_losses, label="Discriminator Loss")
            plt.plot(g_losses, label="Generator Loss")
            plt.xlabel("Iterations")
            plt.ylabel("Loss")
            plt.legend()
            plt.title("Generator and Discriminator Loss During Training")
            plt.savefig(f'GTSRB/Test/loss_plot_epoch_{epoch}_step_{i}.png')
            plt.close()  # Close the plot to free up memory

